{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3949e681-4967-43a6-9511-9143cd7a8e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amrab\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "from skimage.transform import rotate\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import rotate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15dae320-cf77-4fb7-8e93-c2ec51b868fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract HOG features from an image\n",
    "def extract_hog_features(img):\n",
    "    # Convert the image to grayscale if it's not already\n",
    "    if img.ndim > 2:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Compute HOG features\n",
    "    hog_features, _ = hog(img, orientations=8, pixels_per_cell=(8, 8),\n",
    "                          cells_per_block=(2, 2), block_norm='L2-Hys', visualize=True)\n",
    "\n",
    "    # Rescale intensity for better visibility of HOG features\n",
    "    hog_features_rescaled = exposure.rescale_intensity(hog_features, in_range=(0, 10))\n",
    "\n",
    "    return hog_features_rescaled.flatten()\n",
    "\n",
    "# Function to extract color-based features (mean of RGB channels)\n",
    "def extract_color_features(img):\n",
    "    color_features = np.mean(img, axis=(0, 1))\n",
    "    return color_features\n",
    "\n",
    "# Data augmentation function\n",
    "def augment_image(img):\n",
    "    # Perform rotation by a random angle between -10 and 10 degrees\n",
    "    angle = np.random.uniform(-10, 10)\n",
    "    augmented_img = rotate(img, angle, mode='reflect', preserve_range=True).astype(np.uint8)\n",
    "    return augmented_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "675a1e92-9301-42b2-88e4-2e0812f861dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the dataset\n",
    "data_dir = r\"Images\"  # Replace with the actual path\n",
    "\n",
    "# Lists to store features and labels\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Loop through each class (breed) in the dataset\n",
    "for breed_folder in os.listdir(data_dir):\n",
    "    breed_path = os.path.join(data_dir, breed_folder)\n",
    "    \n",
    "    # Loop through each image in the breed folder\n",
    "    for img_name in os.listdir(breed_path):\n",
    "        img_path = os.path.join(breed_path, img_name)\n",
    "        \n",
    "        # Read the image\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "        \n",
    "        # Resize the image (optional, but can be useful for consistency)\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "        \n",
    "        # Extract HOG features\n",
    "        hog_features = extract_hog_features(img)\n",
    "        \n",
    "        # Extract color features\n",
    "        color_features = extract_color_features(img)\n",
    "        \n",
    "        # Append features and labels to the lists\n",
    "        features.append(np.concatenate((hog_features, color_features)))\n",
    "        labels.append(breed_folder)\n",
    "        \n",
    "        # Augment the image and extract features from augmented image\n",
    "        augmented_img = augment_image(img)\n",
    "        augmented_hog_features = extract_hog_features(augmented_img)\n",
    "        augmented_color_features = extract_color_features(augmented_img)\n",
    "        \n",
    "        # Append features and labels from augmented image\n",
    "        features.append(np.concatenate((augmented_hog_features, augmented_color_features)))\n",
    "        labels.append(breed_folder)\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fa7d210-416b-48b5-a668-15f1a21b5984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataset\n",
    "indices = np.arange(features.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "features = features[indices]\n",
    "labels = labels[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50ff9066-ae10-4fbd-a24f-b59925872ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the labels into numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f62264d6-7b42-4802-b18d-18bf1ba1ef68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, validation, and testing sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(features, encoded_labels, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf837dc-091c-48c3-a822-daaca0999842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create logistic regression classifier with grid search for hyperparameter tuning\n",
    "param_grid = {'C': [0.1, 1, 10], 'max_iter': [500, 1000, 2000]}\n",
    "logreg_model = GridSearchCV(LogisticRegression(solver='lbfgs', multi_class='auto'), param_grid, cv=3)\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = logreg_model.predict(X_val)\n",
    "\n",
    "# Decode the predicted labels back to breed names\n",
    "decoded_val_predictions = label_encoder.inverse_transform(y_val_pred)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = logreg_model.predict(X_test)\n",
    "# Decode the predicted labels back to breed names\n",
    "decoded_test_predictions = label_encoder.inverse_transform(y_test_pred)\n",
    "# Evaluate the accuracy on the test set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}\")\n",
    "\n",
    "# Evaluate the accuracy on the validation set\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}\")\n",
    "\n",
    "print(\"Best parameters found by grid search:\", logreg_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed57b3a6-5eeb-4e4c-9a68-88ca42541a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the logistic regression model on the full training set\n",
    "final_logreg_model = LogisticRegression(solver='lbfgs', multi_class='auto', **logreg_model.best_params_)\n",
    "final_logreg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847e8f5a-52ff-445f-97c2-aab8eefecc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}\")\n",
    "print(\"Best parameters found by grid search:\", logreg_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7db17b9-6a29-437b-85c9-3ef5d13a770e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Lists to store accuracy and iteration number ( number of times the algorithm goes through the entire dataset )\n",
    "accuracies = []\n",
    "iterations = []\n",
    "\n",
    "# Vary the max_iter parameter\n",
    "for max_iter in range(1, 101, 5):\n",
    "    # Create logistic regression model\n",
    "    model = LogisticRegression(max_iter=max_iter, solver='lbfgs', multi_class='auto', random_state=42)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    y_val_pred = model.predict(X_val_scaled)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    # Store accuracy and iteration number\n",
    "    accuracies.append(accuracy)\n",
    "    iterations.append(max_iter)\n",
    "\n",
    "# Plot the learning curve\n",
    "plt.plot(iterations, accuracies, marker='o')\n",
    "plt.title('Learning Curve for Logistic Regression')\n",
    "plt.xlabel('Number of Iterations')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc66479-13db-48b7-8d6b-998c1e5a4827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3276b72-5ac1-436e-98b7-867bada1e260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC curve for each class on the validation set\n",
    "num_classes = len(np.unique(encoded_labels))\n",
    "fpr_val = dict()\n",
    "tpr_val = dict()\n",
    "roc_auc_val = dict()\n",
    "\n",
    "classifier = final_logreg_model\n",
    "\n",
    "for i in range(num_classes):\n",
    "    y_true = (y_val == i)\n",
    "    y_score = classifier.predict_proba(X_val)[:, i]\n",
    "    fpr_val[i], tpr_val[i], _ = roc_curve(y_true, y_score)\n",
    "    roc_auc_val[i] = auc(fpr_val[i], tpr_val[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda3ac93-b8cf-435d-b71e-2dee89051323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves on the validation set\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(num_classes):\n",
    "    plt.plot(fpr_val[i], tpr_val[i], label=f'Class {i} (AUC = {roc_auc_val[i]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Each Class (Validation Set)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abcad64-2e6c-440a-be89-3e8055533bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the features from training and testing sets\n",
    "all_features = np.vstack([X_train, X_test])\n",
    "\n",
    "# Choose the number of clusters (k)\n",
    "k = 5  # You can adjust this based on your requirements\n",
    "\n",
    "# Fit KMeans model\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "kmeans.fit(all_features)\n",
    "\n",
    "# Get cluster labels for training and testing sets\n",
    "train_cluster_labels = kmeans.predict(X_train)\n",
    "test_cluster_labels = kmeans.predict(X_test)\n",
    "\n",
    "# Display the cluster labels for a few samples\n",
    "print(\"Training Set Cluster Labels:\", train_cluster_labels[:10])\n",
    "print(\"Testing Set Cluster Labels:\", test_cluster_labels[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d2549c-9fd1-4519-8a7e-94507be8d141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate features for training and testing sets\n",
    "all_features = np.vstack([X_train, X_test])\n",
    "\n",
    "# Fit PCA model\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "pca_result = pca.fit_transform(all_features)\n",
    "\n",
    "# Add cluster labels to the PCA results\n",
    "pca_df = pd.DataFrame(data={'PCA1': pca_result[:, 0], 'PCA2': pca_result[:, 1], 'Cluster': np.concatenate([train_cluster_labels, test_cluster_labels])})\n",
    "\n",
    "# Plot the clusters\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(x='PCA1', y='PCA2', hue='Cluster', data=pca_df, palette='viridis', alpha=0.7)\n",
    "plt.title('K-Means Clustering Visualization')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
